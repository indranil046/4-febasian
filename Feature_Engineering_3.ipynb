{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO31CsCINyLMJfkEOg58dF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indranil046/4-febasian/blob/main/Feature_Engineering_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzUR-2ZuQZ5p"
      },
      "outputs": [],
      "source": [
        "1:Min-Max scaling (also called Normalization) is a data preprocessing technique\n",
        "used to rescale features so that they fall within a specific range, usually\n",
        "between 0 and 1.\n",
        "\n",
        "2:The Unit Vector technique (also called vector normalization or scaling to unit\n",
        "norm) is a feature scaling method where each data\n",
        "sample (i.e., row) is scaled such that the entire\n",
        "vector (feature row) has a magnitude (or norm) of 1.\n",
        "\n",
        "3:Principal Component Analysis (PCA) is a statistical technique used for\n",
        "dimensionality reduction while retaining as much of the variance (information)\n",
        "as possible in the data. PCA works by transforming the original features into a\n",
        " new set of features called principal components, which are linear combinations\n",
        "  of the original features.\n",
        "\n",
        "4:Principal Component Analysis (PCA) and Feature Extraction are closely related\n",
        "concepts in dimensionality reduction, but they serve slightly different purposes.\n",
        " Let's explore their relationship and how PCA is used for feature extraction.\n",
        "\n",
        "5:Min-Max scaling normalizes the features (e.g., price, rating, delivery time)\n",
        "in the food delivery service recommendation system, ensuring that they all lie\n",
        "within a common range and are treated equally by the model. This step is crucial\n",
        " for improving the performance of algorithms that are sensitive to feature scale.\n",
        "\n",
        "6:Using PCA to reduce the dimensionality of a stock price prediction dataset\n",
        "helps capture the most important variance from features like company financial\n",
        "data and market trends. By reducing the number of features, you can create a\n",
        "more efficient, faster, and potentially more accurate model for predicting stock\n",
        " prices.\n",
        "\n",
        "\n",
        "7:Principal Component Analysis (PCA) is a technique used for feature extraction\n",
        "by transforming the original features into a smaller number of principal\n",
        "components (PCs) that explain the most variance in the data. The goal of PCA is\n",
        "to reduce the dimensionality of the dataset while retaining as much of the\n",
        " original variance as possible."
      ]
    }
  ]
}