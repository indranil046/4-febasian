{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5kehu0Nik/n3KnBVzu5tE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indranil046/4-febasian/blob/main/Feature_Engineering_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5-p0fbHR3Wb"
      },
      "outputs": [],
      "source": [
        "1:Using Label Encoding on ordinal data may cause the model to miss the order\n",
        "relationship.\n",
        "\n",
        "Using Ordinal Encoding on nominal data may mislead the model into interpreting\n",
        "an order where none exists.\n",
        "\n",
        "2:When the categorical feature is ordinal or can be meaningfully ordered by the\n",
        "target.\n",
        "\n",
        "When you want the encoding to reflect the relationship between categories and\n",
        "the target.\n",
        "\n",
        "Useful in supervised learning tasks where preserving target-category\n",
        "relationships\n",
        " can improve predictions.\n",
        "\n",
        "Works well when there are many categories, and one-hot encoding would create\n",
        "too many dummy variables.\n",
        "\n",
        "3:Covariance is a statistical measure that indicates the direction of the linear\n",
        " relationship between two variables. It shows whether the variables tend to\n",
        " increase or decrease together.\n",
        "\n",
        "Positive covariance: Both variables tend to increase or decrease together.\n",
        "\n",
        "Negative covariance: One variable tends to increase when the other decreases.\n",
        "\n",
        "Zero covariance: No linear relationship between the variables.\n",
        "\n",
        "4:from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Color': ['red', 'green', 'blue', 'green', 'red'],\n",
        "    'Size': ['small', 'medium', 'large', 'small', 'large'],\n",
        "    'Material': ['wood', 'metal', 'plastic', 'wood', 'metal']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize LabelEncoders for each categorical column\n",
        "le_color = LabelEncoder()\n",
        "le_size = LabelEncoder()\n",
        "le_material = LabelEncoder()\n",
        "\n",
        "# Apply Label Encoding\n",
        "df['Color_Encoded'] = le_color.fit_transform(df['Color'])\n",
        "df['Size_Encoded'] = le_size.fit_transform(df['Size'])\n",
        "df['Material_Encoded'] = le_material.fit_transform(df['Material'])\n",
        "\n",
        "print(df)\n",
        "\n",
        "5:import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Age': [25, 30, 22, 40, 35],\n",
        "    'Income': [50, 60, 45, 80, 70],\n",
        "    'Education_Level': [16, 18, 14, 20, 18]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate covariance matrix\n",
        "cov_matrix = df.cov()\n",
        "\n",
        "print(cov_matrix)\n",
        "\n",
        "6:For Gender, if you want a simpler representation or if the algorithm handles\n",
        "categorical variables well, Label Encoding might be enough. But One-Hot Encoding\n",
        " is safer.\n",
        "\n",
        "For Education Level and Employment Status, ordinal encoding captures meaningful\n",
        " rank information which can improve model performance.\n",
        "\n",
        "7:import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Temperature': [25, 28, 22, 30, 26],\n",
        "    'Humidity': [55, 60, 58, 62, 59],\n",
        "    'Weather_Condition': ['Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Cloudy'],\n",
        "    'Wind_Direction': ['North', 'South', 'East', 'West', 'North']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Encode categorical variables\n",
        "weather_mapping = {'Sunny': 0, 'Cloudy': 1, 'Rainy': 2}\n",
        "wind_mapping = {'North': 0, 'South': 1, 'East': 2, 'West': 3}\n",
        "\n",
        "df['Weather_Encoded'] = df['Weather_Condition'].map(weather_mapping)\n",
        "df['Wind_Encoded'] = df['Wind_Direction'].map(wind_mapping)\n",
        "\n",
        "# Calculate covariance matrix\n",
        "cov_matrix = df[['Temperature', 'Humidity', 'Weather_Encoded', 'Wind_Encoded']].cov()\n",
        "\n",
        "print(cov_matrix)\n",
        "\n",
        "Covariance involving categorical variables encoded as numbers is often not very\n",
        "meaningful because numeric codes do not reflect true distances or order.\n",
        "\n",
        "For categorical-continuous relationships, consider ANOVA, boxplots, or\n",
        " correlation ratio instead.\n",
        "\n",
        "For categorical-categorical relationships, use chi-square tests or Cram√©r's V."
      ]
    }
  ]
}